import base64
import json
import zlib
from logging import getLogger
from queue import Queue
from typing import Any, Generator, Iterable

from malduck.extractor import ExtractManager, ExtractorModules
from malduck.procmem import ProcessMemory
from scalpl import Cut

from elastic.malware_config_extractor.thread import BaseThread
from elastic.malware_config_extractor.utils import consume_queue

logger = getLogger(__name__)


class MalduckTransform(BaseThread):
    def __init__(self, config: Cut, taskq: Queue, outq: Queue, **kwargs) -> None:
        super().__init__(**kwargs)

        self.config: Cut = config
        self.modules = None
        self.samples = None
        self.taskq = taskq
        self.outq = outq

        logger.debug(f"Parsed input config: {self.config}")

    def _setup_modules(self):
        # Set up the module paths.
        if self.config["modules"]:
            logger.info("Getting os path of malduck modules...")
            self.modules = (
                self.config["modules"]
                if self.config["modules"]
                else logger.error("Please specify Malduck module path.")
            )

        extractor_modules = ExtractorModules(modules_path=self.modules)
        self.extract_manager = ExtractManager(extractor_modules)

        if not self.extract_manager.extractors:
            logger.exception(f"[!] No extractor modules found under '{self.modules}'!")

    def process_configs(self, extract_manager):
        if extract_manager.config:
            for config in extract_manager.config:
                family = config["family"]
                logger.info(f"[+] Ripped '{family}' configuration:")
                logger.debug(config)
                yield config

    def transform(self) -> Iterable[dict[str, Any]]:

        # self.done is a threading Event (see .thread.WaitableEvent)
        # that is False unless an unhandled exception occurs or the
        # main thread calls done.set() to signal that it's time to quit

        while not self.done and not self.quit_when_idle:
            _count: int = 0
            _q: Generator[Any] = consume_queue(self.taskq)

            for doc in _q:
                if self.done:
                    break
                if doc is None:
                    if self.quit_when_idle:
                        break
                    continue

                logger.debug(f"Reading document from queue, it is type {type(doc)}")

                _doc = Cut(doc)
                _bytes_compressed = _doc[
                    "_source.process.Ext.memory_region.bytes_compressed"
                ]
                logger.debug("Decompressing")
                _payload_bytes = zlib.decompress(base64.b64decode(_bytes_compressed))

                # _doc["_src.extraction"] = extraction
                _ = self.extract_manager.push_procmem(
                    ProcessMemory(_payload_bytes), rip_binaries=True
                )

                logger.debug(f"Extracted things: {_}")

                for item in self.process_configs(self.extract_manager):
                    yield item
                    _count += 1

            _q.close()
            logger.info(f"Transform, generated {_count} documents in this batch")

    def run(self) -> None:
        self._setup_modules()

        for item in self.transform():
            self.outq.put(item)

        logger.debug("Waiting to clear the output queue")
        # Wait for the queue to complete before closing this thread
        while self.outq.unfinished_tasks:
            pass

        logger.debug("Shutting down transform")
