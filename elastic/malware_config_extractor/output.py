from logging import getLogger
from queue import Queue
from typing import Any, Generator

from elasticsearch import Elasticsearch
from elasticsearch_dsl import connections
from scalpl import Cut

from elastic.malware_config_extractor.thread import BaseThread
from elastic.malware_config_extractor.utils import connect_elasticsearch, consume_queue
from elastic.malware_config_extractor.mappings import setup_index

logger = getLogger(__name__)


class ESOutput(BaseThread):
    def __init__(
        self, config: Cut, taskq: Queue, do_setup: bool = False, **kwargs
    ) -> None:
        super().__init__(**kwargs)

        self.config: Cut = config
        self.es_client: Elasticsearch = None
        self.do_setup: bool = do_setup
        self.taskq: Queue = taskq

    def _setup_io(self):
        logger.info("Setting up output ES connection")

        if self.config["enabled"] is True:
            logger.info("Connecting to Elasticsearch for output")
            self.es_client = connect_elasticsearch(self.config)

            if self.es_client:
                logger.info("Successfully connected to Elasticsearch for output")
                connections.add_connection("output", self.es_client)

    def setup(self):
        """
        Installs index template and components
        """
        if not self.es_client:
            logger.error("Elasticsearch not connected for output setup!")
            raise ConnectionError("Elasticsearch not connected for output setup")

        setup_index(self.es_client, self.config["index"])

    def load(self) -> None:

        self._setup_io()

        if self.do_setup is True:
            self.setup()

        while not self.done and not self.quit_when_idle:
            _count: int = 0
            _q: Generator[Any] = consume_queue(self.taskq)

            for _doc in _q:
                if self.done:
                    break
                if _doc is None:
                    if self.quit_when_idle:
                        break
                    continue

                _count += 1
                logger.debug(f"Got doc. Type: {type(_doc)}")
                yield _doc

            _q.close()
            logger.info(f"Loaded {_count} documents in this batch")

    def run(self) -> None:

        for doc in self.load():
            self.es_client.index(index=self.config["index"], document=doc)

        logger.debug("Waiting to clear the output queue")
        # Wait for the queue to complete before closing this thread

        logger.debug("Shutting down output")

        # Cleanup
        if self.es_client is not None:
            logger.debug("Closing Elasticsearch output client.")
            self.es_client.close()

        self.done.set()
