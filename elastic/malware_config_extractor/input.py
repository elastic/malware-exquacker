from logging import getLogger
from queue import Queue
from typing import Dict, Generator

from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search, connections
from scalpl import Cut

from elastic.malware_config_extractor.elastic_dsl import get_input_search
from elastic.malware_config_extractor.thread import BaseThread
from elastic.malware_config_extractor.utils import connect_elasticsearch

logger = getLogger(__name__)


class AlertSampleESInput(BaseThread):
    def __init__(
        self,
        config: Cut,
        background: bool,
        poll_interval: int,
        outq: Queue,
        since: str = None,
        before: str = None,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.es_client: Elasticsearch = None
        self.config: Cut = config
        self.background: bool = background
        self.poll_interval: int = poll_interval
        self.since: str = since
        self.before: str = before
        self.taskq: Queue = outq
        logger.debug(f"Parsed input config: {self.config}")

    def _setup_io(self):
        logger.info("Setting up input connection")

        if self.config["enabled"] is True:
            logger.info("Connecting to Elasticsearch for input")
            self.es_client = connect_elasticsearch(self.config)

            if self.es_client:
                logger.info("Successfully connected to Elasticsearch for input")
                connections.add_connection("input", self.es_client)

            _info = self.es_client.info()
            self.source_info: dict[str, str] = {
                "_cluster_info": {
                    "cluster_name": _info["cluster_name"],
                    "cluster_uuid": _info["cluster_uuid"],
                }
            }
        else:
            self.es_client = None
            logger.error("No supported input is enabled. Please configure the input.")

    def extract(self) -> Generator[Dict, None, None]:

        while not self.done:
            _count: int = 0
            logger.info("Retreiving latest results")

            for hit in self.search.scan():
                _count += 1
                logger.debug(f"Extracting document #{_count}")

                doc = {"_source": hit.to_dict()} | hit.meta.to_dict() | self.source_info
                yield doc
                if self.done:
                    logger.debug("Received done signal. Halting input.")
                    break

            logger.info(f"Retrieved {_count} hits")
            # If we're not running as a daemon, stop after one run
            # otherwise, wait for the poll_interval number of minutes
            # if `done` becomes true during this wait, return immediately
            if not self.background or self.done.wait(self.poll_interval * 60.0):
                break

    def run(self):

        self._setup_io()
        self.search: Search = get_input_search(self.config["index"])

        _filter: dict = {"@timestamp": {}}
        if self.since is not None:
            _filter["@timestamp"] |= {"gte": self.since}
        if self.before is not None:
            _filter["@timestamp"] |= {"lt": self.before}

        logger.debug(f"Date filter: {_filter}")
        if _filter["@timestamp"] != {}:
            self.search = self.search.filter("range", **_filter)

        for item in self.extract():
            logger.debug("Writing document to queue")
            self.taskq.put(item)

        logger.debug("Waiting to clear the queue")
        # Wait for the queue to complete before closing this thread
        while self.taskq.unfinished_tasks:
            pass

        # Cleanup
        if self.es_client is not None:
            logger.debug("Closing Elasticsearch input client.")
            self.es_client.close()

        self.done.set()
