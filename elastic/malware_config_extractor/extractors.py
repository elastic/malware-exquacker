import json
import time
from typing import Any, Iterable

from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search, connections
from scalpl import Cut

from elastic.malware_config_extractor import config, utils
from elastic.malware_config_extractor.elastic_dsl import get_input_search

logger = utils.default_logger(__name__)


class BaseExtractor:
    pass


class ESAlertExtractor(BaseExtractor):
    def __init__(
        self,
        config: Cut,
        poll_interval: int,
        since: str | None = None,
        before: str | None = None,
    ) -> None:
        self.es_client: Elasticsearch | None
        self.config: Cut = config
        self.poll_interval: int = poll_interval
        self.since: str | None = since
        self.before: str | None = before

    def _setup_io(self):
        logger.info("Setting up ES connection")

        if self.config["enabled"] is True:
            logger.info("Connecting to Elasticsearch for input")
            self.es_client = utils.connect_elasticsearch(dict(self.config))

            if self.es_client:
                logger.info("Successfully connected to Elasticsearch for input")
                connections.add_connection("input", self.es_client)

            _info = self.es_client.info()
            self.source_info: dict[str, str | dict[str, str]] = {
                "_cluster_info": {
                    "cluster_name": _info["cluster_name"],
                    "cluster_uuid": _info["cluster_uuid"],
                }
            }
        else:
            self.es_client = None
            logger.error("No supported input is enabled. Please configure the input.")

    def generate_query(self) -> None:
        self.search: Search = get_input_search(index=self.config["index"])

        _filter: dict = {"@timestamp": {}}
        if self.since is not None:
            _filter["@timestamp"] |= {"gte": self.since}
        if self.before is not None:
            _filter["@timestamp"] |= {"lt": self.before}

        logger.debug("Date filter: %s", _filter)
        if _filter["@timestamp"] != {}:
            self.search = self.search.filter("range", **_filter)

    def extract(self) -> Iterable[dict[str, Any]]:
        while True:
            _count: int = 0
            logger.info("Retreiving latest results")

            for hit in self.search.scan():
                _count += 1
                logger.debug(f"Extracting document {_count}")

                doc: dict = {"_source": hit.to_dict()} | hit.meta.to_dict() | self.source_info  # type: ignore
                yield doc

            logger.info(f"Retrieved {_count} hits")
            # If we're not running as a daemon, stop after one run
            # otherwise, wait for the poll_interval number of minutes
            time.sleep(self.poll_interval * 60.0)


class FileAlertExtractor(BaseExtractor):
    def __init__(
        self,
        input_file: str,
        poll_interval: int = 1,
    ) -> None:
        self.input_file: str = input_file
        self.poll_interval: int = poll_interval

    def _setup_io(self):
        logger.info("Setting up file connection")

        with open(self.input_file, "r") as input_file:
            self.input_data = input_file.readlines()

    def extract(self) -> Iterable[dict[str, Any]]:
        _count = 0
        logger.info("Retreiving latest results")

        for line in self.input_data:
            _count += 1
            logger.debug(f"Extracting document {_count}")

            doc: dict = {"_source": json.dumps(line.strip())}
            yield doc

        logger.info(f"Retrieved {_count} hits")
